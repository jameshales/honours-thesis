\chapter{Literature review}\label{litreview}

We review previous techniques for modelling information change in epistemic
logic and doxastic logic, and previous work in the refinement quantified modal
logic, that motivates the present work.

\section{Information change in epistemic logics}

Dynamic epistemic logic is a general term for the study of information change in
modal epistemic systems. Information change is performed by informative updates,
events that provide agents with additional information, whilst leaving factual
information about the state of the world unchanged. Notable representations for
informative updates in dynamic epistemic logic include {\em public
announcements} and {\em action models}. I will briefly discuss these
representations of informative updates, and the logics that have been devised to
reason about them.

\subsection{Public announcements}

A public announcement is a simple form of informative update, where a true
statement is announced to all agents in a system at
once~\cite{vanditmarsch2007dynamic}.  A public announcement takes the form of an
epistemic formula $\alpha$. As $\alpha$ is announced to all agents at once, one
result of the announcement is that afterwards every agent knows that $\alpha$ is
true. In addition to this, as the announcement was made publicly, it becomes
{\em common knowledge}. Common knowledge means that every agent knows $\alpha$,
every agent knows that every agent knows that $\alpha$, and so on ad infinitum.
In terms of the Kripke model representation of the epistemic system, a public
announcement has the effect of restricting the states of the Kripke model to
those states that are consistent with $\alpha$, as given the additional
information that $\alpha$ is the case, those states that are inconsistent with
$\alpha$ are now considered impossible by every agent.

The public announcement logic was axiomatised by Plaza~\cite{plaza2007logics},
and also independently by by Gerbrandy and
Groenvald~\cite{gerbrandy1997reasoning}.  The logic introduces an operator
$[\alpha]$, where $\alpha$ is an epistemic formula, that can be used to reason
about the results of a specific public announcement. The operator $[\alpha]
\phi$ means that after the formula $\alpha$ is publicly announced, $\phi$ holds
in the resulting epistemic state. This allows one to reason about the
consequences of specific public announcements in the epistemic system.

Public announcements are a very limited form of informative update, because the
information contained in a public announcement necessarily becomes common
knowledge to all agents in the system. Public announcements cannot for example
model informative updates that provide information privately to only some of
the agents in the system. Public announcements are however suited to some
interesting problems, for example the muddy children puzzle that was discussed
in the introduction to this thesis.

\subsection{Action models}\label{litreview-am}

Action models capture a more general notion of informative updates than public
announcements. Compared to public announcements, action models are able to
represent informative updates that provide information to only a subset of the
agents, or where an agent may be aware that one of several possible informative
updates has occurred, but is uncertain as to which update actually occurred. 

For example, suppose that Alice and Bob have made a bet on the flip of a coin.
Alice flips the coin, and holds it on the back of her hand so that neither
person can see what it is initially. Neither Alice nor Bob know whether the coin
landed on heads or tails, and each of them knows that the other is ignorant of
the result of the flip (i.e. it is common knowledge). Alice then lifts her hand,
and without letting Bob see the coin, sees that the coin landed on heads. Bob
saw Alice do this, but he didn't see what the coin landed on. The act of Alice
looking at the coin is an informative update, one result of which is that Alice
now knows that the coin landed on heads, whilst Bob still doesn't know. Thus the
effect of this informative update was to provide different information to Alice
than to Bob.  Furthermore, Bob saw Alice look at the coin, so he's aware that an
informative update has occurred, but is uncertain as to which update actually
occurred. From the point of view of Bob, Alice may have learned that the coin
landed on heads, or that it landed on tails; Bob cannot distinguish between
these two possibilities. Thus Bob now knows that either Alice knows that the
coin landed on heads, or that Alice knows that the coin landed on tails, but
doesn't know which is actually the case.

Action models are represented by relational structures, similar to Kripke
models~\cite{vanditmarsch2007dynamic}. An action model is executed on a Kripke
model, resulting in a new Kripke model. If the action model is said to represent
an informative update, then the new Kripke model represents the resulting
knowledge state after the informative update has been performed.

The logic of action models was introduced by Baltag, Solecki and
Moss~\cite{baltag2004logics}. Again, an operator is introduced that has the
effect of performing an informative update, this time in the form of executing
an action model on the Kripke model that represents the current epistemic
state.  The operator $[\mathrm{M,s}]\phi$ means that after the action model
$(\mathrm{M, s})$ is executed in the current epistemic state, $\phi$ holds in
the resulting epistemic state. 

Epistemic actions are a similar representation of informative updates.
van
Ditmarsch~\cite{vanditmarsch1999logic,vanditmarsch2001knowledge,vanditmarsch2007dynamic}
introduced the logic of epistemic actions, a logic similar to the logic of
action models. The difference between epistemic actions and action models is
that an epistemic action is represented as a formula instead of as a relational
structure. The formula may contain operators whose purpose is to limit the
effect of informative updates to a certain subset of agents, or to give the
effect that one of several informative updates may have taken place, but from
the point of view of some of the agents, which update has actually occurred is
unclear. This can be compared to a public announcement, which is also
represented as a formula.

\subsection{Arbitrary public announcement logic}

Balbiani, Baltag, van Ditmarsch, et al.~\cite{balbiani2007arbitrary} introduced
the arbitrary public announcement logic, an extension of the public announcement
logic, that provides an operator for quantifying over arbitrary public
announcements. It introduces an operator, $\Box\psi$, which means that after
any arbitrary public announcement, $\psi$ holds. Its dual operator,
$\Diamond\psi$ means that after some public announcement, $\psi$ holds.

The same paper briefly discusses a possible arbitrary action model logic, a
generalisation of arbitrary public announcement logic allowing for any kind of
informative update, modelled as the execution of an action model. French and
van Ditmarsch~\cite{french2008undecidability} later showed that the arbitrary
public announcement was undecidable. Whilst the arbitrary action model logic has
not been considered in depth, the undecidability result in arbitrary public
announcement logic has encouraged research into weaker versions of this logic
instead, as they are more likely to be decidable.

\section{Information change in doxastic logics}

In dynamic epistemic logic, we consider how knowledge changes in response to
informative updates that provide agents with additional information. A key
property of epistemic systems is that everything that an agent knows must be
true, and any information that an agent is provided must also be true. A
consequence of this is that once agents have gained certain information, they do
not lose this information; further informative updates cannot cause the agent to
forget past information, or to reconsider the truth of previous statements. By
contrast, in doxastic systems, the beliefs that an agent holds do not
necessarily have to be true, and the information that agents are given also do
not have to be true. Therefore it is reasonable for an agent to reconsider its
beliefs, and possibly reject past information, if it is provided with new
information that contradicts its old beliefs. We will briefly discuss {\em
belief revision}, which models the revision and possible removal of old beliefs,
and {\em action models}, which can be generalised from epistemic systems to
doxastic systems.

\subsection{Belief revision}

The AGM approach to belief revision, named for Alchourr√≥n, G{\"a}rdenfors and
Makinson~\cite{alchourron1985logic}, who did much of the initial work in this
area, considers the beliefs of an agent as a set of propositional formulae,
called the belief set, that the agent believes to be true. Informative updates
are represented by an operation on the belief set, called a {\em revision},
wherein a new propositional formula is incorporated into the belief set, and the
existing beliefs are revised to accommodate it. The process of belief revision
involves adding the new information to the belief set, whilst rejecting existing
beliefs that may contradict with the new information. Revision can be defined as
an operation over a set of propositional formulae, and so reasoning about belief
revision can be done directly in these terms. Dynamic doxastic logic is a logic
similar to the previously discussed public announcement logics, and action model
logics, which introduces an operator for reasoning about the result of an
informative update in terms of belief revision~\cite{vanditmarsch2007dynamic}.
Variants of dynamic doxastic logic use different operators for belief revision.
Segerberg~\cite{segerberg2001basic} provided axiomatisation for some variants of
dynamic doxastic logics.

\subsection{Action models}\label{litreview-am-kd45}

The same system of action models for modelling informative updates in epistemic
models can be generalised to apply to doxastic
models~\cite{vanditmarsch2007dynamic}. Unlike action models applied in the
epistemic setting, action models applied in the doxastic setting do not
necessarily have to represent a truthful informative update, so it is possible
for agents to come to believe statements that are not actually true. By contrast
to belief revision, it is not possible for action models to cause an agent to
reject past information. In effect, once an agent has been provided with
information, it is committed to believe that information forever. 

It is also possible for an action model to cause a belief that was once founded
to become unfounded. For example, in the previous coin flipping example, if
Alice had taken a peek at the coin without Bob's seeing her do so, then the
result of this is that Alice now believes that the coin landed on heads, whilst
Bob continues to believe (incorrectly) that Alice does not believe either way
that the coin landed on heads or tails. Bob continues to hold his initial belief
because he has not been exposed to any information that would cause that belief
to change. Such a change is not permissible in an epistemic setting, where
knowledge must be founded, but it is permissible in a doxastic setting, where
beliefs are allowed to be unfounded.

\section{Other related logics}

\subsection{Group announcement logics}

The group announcement logic, introduced by {\AA}gotnes et
al.~\cite{agotnes2010group} is an extension of public announcement logic that
allows one to reason about whether a group of agents within an epistemic system
are able to cooperate in order to bring about some knowledge state. The agents
in the group are able to cooperate by publicly announcing statements that the
agents know, but are unable to announce statements that they do not know. The
logic introduces an operator, $<G>$, where $G$ is a subset of the agents, and
the formula $<G> \phi$ means that there is some set of formulae, such every
formula is known by at least one of the agents in $G$, and such that after each
agent announces the formulae that they know, $\phi$ is true in the resulting
knowledge state. {\AA}gotnes et al.~\cite{agotnes2010group} provide a sound and
complete axiomatisation of the group announcement logic, show that it is
decidable, and give complexity and expressivity results for the logic. Notably,
the group announcement logic is not as expressive as the arbitrary public
announcement logic, and it is conjectured that the arbitrary public announcement
is not as expressive as the group announcement logic either.  The difference
between group announcement logic and the arbitrary public announcement logic is
that the group announcement logic essentially quantifies over the public
announcements that the agents in the group know, whereas the arbitrary public
announcement logic quantifies over all possible public announcements.

\subsection{Propositional dynamic logics}

Propositional dynamic logic is a variant of dynamic logic, first introduced by
Fischer and Ladner~\cite{fischer1979propositional}. Propositional dynamic logic
is a logic that introduces a concept of performing an action, called a program,
on a modal state. The programs in propositional dynamic logic are symbolic in
nature, and do not have any inherent effect on the model that it is performed
on. Programs can be combined, by composition, repetition, concurrent execution
or by including a test, where an action is performed only if a particular
formula is satisfied at the current state. Actions are performed using modal
operators that are labelled with the actions themselves; hence there is a modal
operator for every possible action. What differentiates propositional dynamic
logics from standard modal logics is that the models under consideration have
algebraic constraints on them, which preserve certain properties about the
composition of programs, amongst other properties. Propositional dynamic logic
is decidable, and has decision procedures which have an exponential running time
in the worst case~\cite{pratt1980near}.

van Benthem, van Eijck and Kooi~\cite{vanbenthem2006logics} showed that the
action model logic can be translated to propositional dynamic logic, and hence
propositional dynamic logic is at least as expressive as the action model logic.
Miller and Moss however showed that adding quantification over action models,
as in arbitrary action model logic, makes the logic
undecidable~\cite{miller2005undecidability}.

\subsection{Description logics}

Description logics are logics used for knowledge representation, often used in
applications involving ontologies, such as artificial intelligence or the
Semantic Web. Description logics are similar to modal logics, in the sense that
they are designed to be decidable fragments of first-order logic, and in fact
many description logics are simply syntactic variations of modal
logics~\cite{blackburn2002modal}. Dynamic description logics, a hybrid of
propositional dynamic logics and description logics have been considered by
Wolter and Zakharyaschev~\cite{wolter1998dynamic}. Wolter and Zakharyaschev
extended the description logic $\mathcal{ALC}$, which is a syntactic variation of
the modal logic \logicK{}, with propositional dynamic operators, provided an
axiomatisation for the resulting logic and showed that it was decidable.

\subsection{Bisimulation quantified modal logics}

Bisimulations are a relationship between Kripke models, that preserves the truth
of modal formulae interpreted over the related Kripke models. Bisimulations are
defined formally in Section~\ref{bisimulation}. Bisimulation quantified modal
logics extend modal logics with an operator for quantifying over the models that
are bisimilar to the Kripke model under consideration, but where a particular
propositional atom may vary in its interpretation. In effect it is quantifying
over the truth value of a propositional variable, in models bisimilar to the
current Kripke model.  French~\cite{french2006bisimulation} considered a number
of bisimulation quantified modal logics, and provided a translation to the
modal $\mu$-calculus, and decidability or undecidability results for several
such logics. The notion of a bisimulation is related to the notion of a
refinement, on which the refinement quantified modal logics are based.

\section{Refinement quantified modal logics}

The future event logic, introduced by van Ditmarsch and
French~\cite{french2009simulation} logic, is an extension of epistemic logic
that provides an operator for quantification over arbitrary refinements of
Kripke models. The semantics of the logic were provided by van Ditmarsch and
French, along with several results and comparisons to justify the future event
logic as accurately capturing the notion of quantifying over arbitrary
informative updates. The semantics of the future event logic was also compared
to previously defined logics, in particular to the bisimulation quantified
epistemic logic, and to the proposed arbitrary action model logic.  In this
thesis we refer to the future event logic with the more general term of
refinement quantified modal logics. The future event logic that van Ditmarsch
and French initially introduced is the epistemic variant, the refinement
quantified epistemic logic.

In their paper, van Ditmarsch and French~\cite{french2009simulation} briefly
relate the refinement quantified modal logics to the bisimulation quantified
modal logics.  The notion of bisimulations and refinements are related, in that
the refinement relation is a pre-order relation, and the bisimulation relation
is the equivalence relation that is naturally induced from this pre-order.
However the two kinds of logics vary significantly in their interpretations, as
the bisimulation quantifiers bind propositional variables, whilst the
refinement quantifiers do not bind any variables. % TODO - deeper
relationships?

A comparison was also given by van Ditmarsch and French to the proposed
arbitrary action model logic~\cite{french2009simulation}. The main difference
between the two logics is that the refinement quantified epistemic logic does
not include an operator for reasoning about the results of a specific
informative update. van Ditmarsch and French~\cite{french2009simulation} show
that if such an operator is added to the refinement quantified epistemic logic,
then the resulting logic is equivalent to the arbitrary action model logic. The
semantics of the refinement quantifier in the refinement quantified epistemic
logic are much simpler than the semantics of the action model quantifier in
arbitrary action model logic, as they do not rely on the mechanics of action
models.

Although not considered in detail by van Ditmarsch and French, we compare the
related refinement quantified doxastic logic to previously defined notions of
information change in doxastic logics. The refinement quantified epistemic logic
quantifies over the refinements of Kripke models, which are equivalent to the
execution of arbitrary action models on the Kripke
model~\cite{french2009simulation}. A consequence of this in the doxastic setting
is that the notion of information change that the refinement quantified doxastic
logic captures is closer to that of the action models that we have discussed
earlier, rather than belief revision. In particular, this means that agents are
committed to believing information after it has been provided to them, and that
it is not possible for agents to reject information that they have previously
been provided.

The refinement quantified modal logic is considered in more depth by van
Ditmarsch, French and Pinchinat~\cite{french2010future}. They consider the
single-agent modal variant of the logic, rather than the epistemic variant. An
axiomatisation of the logic is provided, and is proven sound and complete. The
completeness proof for the axiomatisation is performed via a provably correct
translation to single-agent modal logic. This translation shows that the
single-agent refinement quantified modal logic is expressively equivalent to the
single-agent modal logic. This expressivity result gives us several results
about the single-agent refinement quantified modal logic from properties of
basic modal logic, in particular that the single-agent refinement quantified
modal logic is decidable. An explicit decision procedure was also given by van
Ditmarsch, French and Pinchinat, that runs in 2EXP time using a tableau method,
which gives an upper bound for the complexity of the logic. The refinement
quantified modal logic is also shown to be exponentially more succinct than the
basic modal logic, a result that hints that the decision procedure that was
given is likely to be optimal. Extending the refinement quantified modal logic
to the multi-agent cases, and to epistemic and doxastic variants, are left as
future work.
