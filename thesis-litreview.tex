\chapter{Literature review}

We review previous techniques in dynamic epistemic logic and dynamic doxastic
logic, and previous work in the future event logic, that motivates the present
work.

\section{Dynamic epistemic logic}

Dynamic epistemic logic is the study of information change in modal epistemic
systems. Information change is performed by informative updates, events that
provide agents with additional information, whilst leaving factual information
about the state of the world unchanged. Notable representations for informative
updates in dynamic epistemic logic include {\em public announcements} and {\em
action models}. I will briefly discuss these representations of informative
updates, and the logics that have been devised to reason about them.

\subsection{Public announcements}

A public announcement is a simple form of informative update, that can be
thought of as information that is announced to all agents in an epistemic system
at once. A public announcement takes the form of an epistemic formula $\phi$.
The result of a public announcement is that every agent knows $\phi$, every
agent knows that every other agent knows $\phi$, and so on, ad infinitum. In
terms of the Kripke model representation of the epistemic system, a public
announcement has the effect of restricting the states of the Kripke model to
those that are consistent with $\phi$; given the additional information $\phi$,
the states that are not consistent with $\phi$ are now considered inplausible by
every agent, and so these states are removed.

The public announcement logic was introduced and axiomatised by
Plaza~\cite{plaza2007logics}, and also independently by by Gerbrandy and
Groenvald~\cite{gerbrandy1997reasoning}.  The logic introduces an operator
$[\alpha]$, where $\alpha$ is an epistemic formula, that can be used to reason
about the results of a specific public announcement. The operator, $[\alpha]
\phi$ means that after the formula $\alpha$ is publicly announced, $\phi$ holds
in the resulting epistemic state. This allows one to reason about the
consequences of specific public announcements in the epistemic system.

Public announcements are a very limited form of informative update, because the
information contained in a public announcement necessarily becomes common
knowledge to all agents in the system. Public announcements cannot for example
model informative updates that provide information privately to only some of
the agents in the system. Public announcements are however suited to some
interesting problems, for example the muddy children puzzle that was discussed
in the introduction to this paper~\cite{vanditmarsch2007dynamic}.

\subsection{Action models}

Action models capture a more general notion of informative updates than public
announcements. Compared to public announcements, action models are able to
represent informative updates that provide information to only a subset of the
agents, or where an agent may be aware that one of several possible informative
updates has occurred, but is uncertain as to which update actually occurred. 

For example, we may have a situation with two agents, $a$ and $b$, where neither
agent knows whether a proposition $p$ is true or false, and moreover, both
agents know about the other's ignorance. There may be an informative update
where $a$ is told privately that $p$ is in fact true, and although $b$ cannot
overhear this information, $b$ is still aware that some private communication
has taken place. The result of this is that $a$ now knows that $p$ is true,
whilst $b$ still does not know whether $p$ is true or false i.e.  the
informative update has provided information to only one of the agents.
Furthermore, whereas before the informative update, $b$ knew that $a$ didn't
know whether $p$ was true or false, after the informative update this is no
longer the case. Although $b$ is aware that an informative update has
occurred, $b$ is uncertain as to which update has actually occurred; from the
point of view of $b$, it is possible that $a$ was told that $p$ is true, or that
$a$ was told that $p$ is false, or even that $a$ was not told anything at all.
Thus $b$ now considers it possible that $a$ knows whether $p$ is true or false,
and so $b$ no longer knows that $a$ is unaware of the truth of $p$.

Action models are a graph structure, similar to a Kripke model, that represents
an informative update. The nodes of the action model, called the action points,
are labelled with epistemic formulae, called preconditions, whilst the edges of
the action model are labelled with agents, similar to a Kripke model. An action
model is executed on a Kripke model, giving a new Kripke model that represents
the knowledge state resulting from the informative update that the action model
represents. The states of the new Kripke model are the Cartesian product of the
states of the original Kripke model, and the action points of the action model,
restricted so that a state is only paired with an action point when the state in
the original Kripke model satisfies the precondition that labels the action
point. An edge is formed between a state in the new Kripke model where there was
an edge between the corresponding states in the original Kripke model, and an
edge between the corresponding action points. The valuation of a state in the
new Kripke model comes from the valuation of the corresponding state in the
original Kripke model.

The power of action models comes from the restrictions caused by the
preconditions that label the action points. The preconditions restrict the
adjacent states in the new Kripke model, to states that satisfied the
precondition in the original Kripke model. This restriction potentially has the
effect of providing the agent with additional information.  As the edges of the
action model are labelled with agents, different agents may have different
preconditions in adjacent action points. Thus different information can be
provided to different agents. As multiple preconditions may be satisfied at a
state in the original Kripke model, several sets of restrictions may apply at
that state. This has gives effect of performing an informative update, where the
agent is aware that an informative update has occurred, but is uncertain as to
which specific informative update has actually occurred. Again, as the edges of
the action model are labelled with agents, this effect can be different for
different agents.

The logic of action models was introduced by Baltag, Solecki and
Moss\cite{baltag2004logics}. Again, an operator is introduced that has the
effect of performing an informative update, this time in the form of executing
an action model on the Kripke model that represents the current epistemic
state.  The operator, $[\mathrm{M,s}]\psi$ means that after the action model
$(\mathrm{M, s})$ is executed in the current epistemic state, $\psi$ holds in
the resulting epistemic state. 

Epistemic actions are a similar representation of informative updates.
van
Ditmarsch~\cite{vanditmarsch1999logic,vanditmarsch2001knowledge,vanditmarsch2007dynamic}
introduced the logic of epistemic actions, a logic similar to the logic of
action models. The difference between epistemic actions and action models is
that an epistemic action is represented as a formula, similar to a
generalisation of a public announcement, with special operators used to provide
different information to different agents, or to provide agents with uncertainty
as to which informative update has actually occurred.

\subsection{Arbitrary public announcement logic}

Balbiani, Baltag, van Ditmarsch, et al.\cite{balbiani2007arbitrary} introduced
the arbitrary public announcement logic, extension of the public announcement
logic, that provides an operator for quantifying over arbitrary public
announcements. It introduces an operator, $\Box\psi$, which means that after
any arbitrary public announcement, $\psi$ holds. Its dual operator,
$\Diamond\psi$ means that after some public announcement, $\psi$ holds.

The same paper briefly discusses a possible arbitrary action model logic, a
generalisation of arbitrary public announcement logic allowing for any kind of
informative update, modelled as the execution of an action model. French and
van Ditmarsch~\cite{french2008undecidability} later showed that the arbitrary
public announcement was undecidable. Whilst the arbitrary action model logic has
not been considered in depth, the undecidability result in arbitrary public
announcement logic has encouraged research into weaker versions of this logic
instead, as they are more likely to be decidable.

\section{Dynamic doxastic logic}

Dynamic doxastic logic is the study of information change in modal doxastic
systems. In dynamic epistemic logic, we consider how knowledge changes in
response to informative updates that provide agents with additional information.
A key property of epistemic systems is that everything that an agent knows must
be true. A consequence of this is that once agents have gained knowledge
(specifically, positive knowledge), they do not lose this knowledge; further
informative updates cannot cause the agent to forget past information, or to
reconsider the truth of particular statements. By contrast, in doxastic systems,
the beliefs that an agent holds do not necessarily have to be true, and so it is
reasonable for an agent to reconsider its beliefs if it is provided with new
information that contradicts its old beliefs. Two notable representations of
informative updates in doxastic logic include {\em action models} and {\em
belief revision}, which we discuss briefly.

\subsection{Action models}

The same system of action models for modelling informative updates in epistemic
models can be generalised to apply to doxastic models. Unlike action models
applied in the epistemic setting, action models applied in the doxastic setting
do not necessarily have to represent a truthful informative update, so it is
possible for agents to come to believe statements that are not actually true.
In the doxastic setting it is also possible for an agent's beliefs to become
invalidated as the result of an informative update, but for the agent to
continue holding those beliefs, oblivious to the changes. 

For example, we may have a situation with two agents, $a$ and $b$, where neither
agent believes either $p$ or $\neg p$, and this fact is a common belief. The
agent $a$ may be told secretly that $p$ is actually the case, whilst $b$ is
unaware that $a$ was told anything at all. The result of this is that $a$ now
believes that $p$, whilst $b$ continues to (falsely) believe that $a$ doesn't
believe that $p$. Such an informative update is not possible in the context of
epistemic logic because everything that an agent knows must be true, and so an
informative update in the epistemic setting cannot result in an agent knowing
something that is false.

Action models however are incapable of {\em revising} beliefs. We have
previously seen that the refinements of a model correspond to the execution of
an action model, and that refinements preserve the truth of positive formulae.
Therefore in the doxastic setting, if an agent holds {\em positive beliefs},
then those beliefs cannot be changed as the result of an action model execution.

\subsection{Belief revision}

The AGM approach to belief revision, named for Alchourrón, Gärdenfors and
Makinson~\cite{alchourron1985logic}, who did much of the initial work in this
area, considers the beliefs of an agent as a set of propositional formulae,
called the belief set, that the agent believes to be true. Informative updates
are represented by an operation on the belief set, called a {\em revision},
wherein a new propositional formula is incorporated into the belief set, and the
existing beliefs are revised to accomodate it. The process of belief revision
involves adding the new information to the belief set, whilst rejecting existing
beliefs that may contradict with the new information. Revision can be
defined as an operation over a set of propositional formulae, and so reasoning
about belief revision can be done directly in these terms. % TODO - read more

\subsection{Action models}

The same system of action models, as applied to epistemic models, can be
generalised to apply to doxastic models.

\section{Other related logics}

\subsection{Group announcement logics}

The group announcement logic, introduced by {\AA}gotnes et
al.~\cite{agotnes2010group} is an extension of public announcement logic that
allows one to reason about whether a group of agents within an epistemic system
are able to cooperate in order to bring about some knowledge state. The agents
in the group are able to cooperate by publically announcing statements that the
agents know, but are unable to announce statements that they do not know. The
logic introduces an operator, $<G>$, where $G$ is a subset of the agents, and
the formula $<G> \phi$ means that there is some set of formulae, such every
formula is known by at least one of the agents, and such that after each agent
announces the formulae that they know, $\phi$ is true in the resulting
knowledge state. {\AA}gotnes et al.~\cite{agotnes2010group} provide a sound and
complete axiomatisation of the group announcement logic, show that it is
decidable, and give complexity and expressivity results for the logic. Notably,
the group announcement logic is not as expressive as the arbitrary public
announcement logic, and it is conjectured that the arbitrary public
announcement is not as expressive as the group announcement logic either.  The
difference between group announcement logic and the arbitrary public
announcement logic is that the group announcement logic essentially quantifies
over the public announcements that the agents in the group know, whereas the
arbitrary public announcement logic quantifies over all possible public
announcements.

\subsection{Propositional dynamic logics}

Propositional dynamic logic is a variant of dynamic logic, first introduced by
Fischer and Ladner~\cite{fischer1979propositional}. Propositional dynamic logic
is a logic that introduces a concept of performing an action, called a program,
on a modal state. The programs in propositional dynamic logic are symbolic in
nature, and do not have any inherent effect on the model that it is performed
on. Programs can be combined, by composition, repetition, concurrent execution
or by including a test, where an action is performed only if a particular
formula is satisfied at the current state. Actions are performed using modal
operators that are labelled with the actions themselves; hence there is a modal
operator for every possible action. What differentiates propositional dynamic
logics from standard modal logics is that the models under consideration have
algebraic constraints on them, which preserve certain properties about the
composition of programs, amongst other properties. Propositional dynamic logic
is decidable, and has decision procedures which have an exponential running time
in the worst case~\cite{pratt1980near}.

van Benthem, van Eijck and Kooi~\cite{vanbenthem2006logics} showed that the
action model logic can be translated to propositional dynamic logic, and hence
propositional dynamic logic is at least as expressive as the action model logic.
Miller and Moss however showed that adding quantification over action models
makes the logic undecidable~\cite{miller2005undecidability}.

\subsection{Description logics}

Description logics are logics used for knowledge representation, often used in
applications involving ontologies, such as artificial intelligence or the
Semantic Web. Description logics are similar to modal logics, in the sense that
they are designed to be decidable fragments of first-order logic, and in fact
many description logics are simply syntactic variations of modal
logics~\cite{blackburn2002modal}.
% TODO - dynamic description logics?

\subsection{Bisimulation quantified logics}

% TODO

\section{Future event logic}

van Ditmarsch and French~\cite{french2009simulation} introduced the future event
logic, an extension of epistemic logic that provides an operator for
quantification over arbitrary refinements of Kripke models. van Ditmarsch and
French provide the semantics of the logic, and provide several results and
comparisons to justify the future event logic as accurately capturing the notion
of quantifying over arbitrary informative updates. van Ditmarsch and French also 
compare the semantics of the future event logic to previously defined logics, in
particular to the bisimulation quantified epistemic logic, and to the proposed
arbitrary action model logic.

The future event logic is related to the bisimulation quantified epistemic
logic, described by French~\cite{french2006bisimulation}, as refinements and
bisimulations are related concepts. The refinement quantifier introduced in the
future event logic can be viewed as a weaker version of the bisimulation
quantifiers in bisimulation quantified epistemic logic. However the two logics
have completely different interpretations and applications with respect to
epistemic logic. A notable difference between the two is that bisimulation
quantifiers quantify over the Kripke models that are bisimilar except for a
given propositional atom $p$, thus the quantifier binds the proposition $p$ as a
variable. This is not the case with the refinement quantifier of the future
event logic. % TODO - applications?

van Ditmarsch and French show that the finite refinements of a Kripke
model are equivalent to the results of executing some action model, and
vice-versa, thus quantifying over refinements is equivalent to quantifying over
the results of action model executions. The future event logic is also compared
to a possible arbitrary action model logic. The main difference between the two
logics is that the arbitrary action model logic also has an operator for
reasoning about the result of a specific action model execution. In fact, van
Ditmarsch and French~\cite{french2009simulation} show that if such an operator
is added to the future event logic, then the resulting logic is equivalent to
the arbitrary action model logic. The semantics of the refinement quantifier in
the future event logic are much simpler than the semantics of the action model
quantifier in arbitrary action model logic, as they do not rely on the mechanics
of action models.

The future event logic is considered in more depth by French, Pinchinat and van
Ditmarsch~\cite{french2010future}. They consider the future event logic as an
extension of single-agent modal logic, rather than considering it as an
extension of epistemic logic, or considering the multi-agent logic.  An
axiomatisation for the logic, and a tableau method for solving the
satisfiability problem are provided. The axiomatisation is shown to be sound and
complete, with the completeness proof performed by a syntactic translation of
formulae in the future event logic into semantically provably equivalent
formulae in modal logic. This translation shows that the future event logic is
no more expressive than modal logic, although a result is given that shows that
the future event logic is exponentially more succinct than modal logic (that is,
some formulae in the future event logic can only be expressed in modal logic by
a formula that is exponentially longer). The expressivity result allows one to
derive decidability results from those results in modal logic, although a
decision procedure is given directly in the setting of the future event logic,
using a tableau method, and this provides an upper bound for the complexity of
the logic. Extending the future event logic to multi-agent modal logic, and to
epistemic and doxastic logics are left as future work.
